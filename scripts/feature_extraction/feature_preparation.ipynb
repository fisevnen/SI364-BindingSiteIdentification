{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir('new-SASA')\n",
    "name_list = [i.rsplit('.',1)[0] for i in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1zoy-C'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenth_same_list = []\n",
    "length_not_same_list = []\n",
    "for i in name_list:\n",
    "    with open('new-SASA/' + i + '.sasa') as f:\n",
    "        sasa_contents = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "    with open('new-fasta/' + i + '.fasta') as g:\n",
    "        fasta_contents = g.read()\n",
    "        g.close()\n",
    "\n",
    "    if len(sasa_contents) == len(fasta_contents) :\n",
    "        lenth_same_list.append(i)\n",
    "    else:\n",
    "        length_not_same_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10282"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lenth_same_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10282/10282 [09:18<00:00, 18.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from itertools import groupby\n",
    "import numpy as np\n",
    "\n",
    "label_dic = {}\n",
    "for i in tqdm(lenth_same_list):\n",
    "    chian_name = i.split('-')[1]\n",
    "    #print(chian_name)\n",
    "    \n",
    "    with open('IFP-renamed/' + i + '.IFP') as f:\n",
    "        IFP_contents = f.readlines()[0][:-1]\n",
    "        f.close()\n",
    "    \n",
    "    with open('new-SASA/'+i+'.sasa') as g:\n",
    "        sasa_list = g.readlines()\n",
    "        g.close()\n",
    "    \n",
    "    IFP_list = IFP_contents.split('|')\n",
    "    #print(IFP_list)\n",
    "    IFP_resn_list = []\n",
    "    for j in IFP_list:\n",
    "        if j[0:1] == chian_name:\n",
    "            if 'HOH' not in j:\n",
    "                ss = [''.join(list(g)) for k, g in groupby(j, key=lambda x: x.isdigit())]\n",
    "                IFP_resn_list.append(ss[-1])\n",
    "    \n",
    "    #print(IFP_resn_list)\n",
    "    result_list = []\n",
    "    for m in sasa_list:\n",
    "        add1 = False\n",
    "        for n in IFP_resn_list:\n",
    "            if m.split()[0] == n:\n",
    "                add1 = True\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "        if add1 == True:\n",
    "            result_list.append('1')\n",
    "        else:\n",
    "            result_list.append('0')\n",
    "    \n",
    "    result_str = ''.join(result_list)\n",
    "    #print(result_str)\n",
    "    #break\n",
    "    with open('new-IFP/' + i + '.IFP', 'w') as g:\n",
    "        g.write(result_str)\n",
    "        g.close()\n",
    "    \n",
    "    label_dic[i] = np.array(result_list).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('part2-label',label_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('part2-index',lenth_same_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10282/10282 [00:58<00:00, 174.90it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from tqdm import tqdm\n",
    "\n",
    "sasa_dic = {}\n",
    "for i in tqdm(lenth_same_list):\n",
    "    with open('new-SASA/' + i + '.sasa', 'r') as f:\n",
    "        contents = f.readlines()\n",
    "        f.close()\n",
    "    \n",
    "    sasa_contents = [j.split(' ')[1][:-1] for j in contents]\n",
    "    tmp = np.array(sasa_contents)\n",
    "    tmp = minmax_scale(tmp)\n",
    "    float64_tmp = tmp.astype(np.float64)\n",
    "    float64_tmp_T = float64_tmp.T\n",
    "    sasa_dic[i] = float64_tmp.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10282/10282 [05:45<00:00, 29.72it/s]\n"
     ]
    }
   ],
   "source": [
    "pssm_dic = {}\n",
    "for i in tqdm(lenth_same_list):\n",
    "    with open('new-pssm/' + i + '.pssm', 'r') as f:\n",
    "        contents = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "    pssm_contents = [j.split()[22:42] for j in contents[3:-6]]\n",
    "    array_test = np.array(pssm_contents)\n",
    "    array_test = array_test.astype(np.float64)\n",
    "    array_test = array_test/100\n",
    "    array_test = array_test.astype(np.float64)\n",
    "    # print(array_test.shape)\n",
    "    pssm_dic[i] = array_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('part2-pssm', pssm_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 4991/10282 [03:10<01:40, 52.45it/s]  "
     ]
    }
   ],
   "source": [
    "SS_dic = {}\n",
    "for i in tqdm(lenth_same_list):\n",
    "    with open('new-ss/%s.ss' %i) as f:\n",
    "        contents = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "    SS_contents = [j.split()[-3:] for j in contents[1:]]\n",
    "    SS_array = np.array(SS_contents)\n",
    "    SS_array = SS_array.astype(np.float64)\n",
    "    SS_dic[i] = SS_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('part2-SS', SS_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30dfeb42b0b98ed617da5993184c470a445e3f60fd08500609c72dd7f0dd0780"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
